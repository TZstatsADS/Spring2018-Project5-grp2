# Load data
df <- read.csv("../data/data.csv", header = TRUE, stringsAsFactors = FALSE)
# Delete the first column from dataset as id won't be used, and delete last column from dataset as its entries are all NA's
df <- df[,-c(1,33)]
# Factorize the diagnosis attribute
df$diagnosis <- factor(df$diagnosis)
df$diagnosis <- as.integer(df$diagnosis)-1   # M=1 B=0
# Split entire data into 80% train set and 20% test set
set.seed(123)
index <- sample(1:nrow(df),0.8*nrow(df))
df.train <- df[index,]
df.test <- df[-index,]
# Check proportion of diagnosis (Benign/Malignant) in train/test sets
#prop.table(table(df.train$diagnosis))
#prop.table(table(df.test$diagnosis))
feature_selected <- c("texture_worst", "area_se", "perimeter_worst",
"concave.points_worst", "concavity_worst", "fractal_dimension_se",
"concavity_se", "texture_se", "smoothness_se",
"smoothness_worst", "fractal_dimension_worst", "symmetry_se",
"symmetry_mean", "symmetry_worst")
df.train2 <- df.train[,c("diagnosis",feature_selected)]
feature_selected <- c("perimeter_worst", "concave.points_worst", "area_se",
"concavity_worst", "texture_worst", "smoothness_worst",
"symmetry_worst", "concavity_se", "fractal_dimension_worst",
"symmetry_mean", "fractal_dimension_se")
df.train2 <- df.train2[,c("diagnosis",feature_selected)]
df.test2 <- df.test[,c("diagnosis",feature_selected)]
run.logi <- TRUE
source("../lib/logi.R")
if(run.logi){
output_logi <- logi(df.train, df.test)
output2_logi <- logi(df.train2, df.test2)
save(output_logi, file = "../output/output_logi.RData")
save(output2_logi, file = "../output/output2_logi.RData")
}else{
load("../output/output_logi.RData")
load("../output/output2_logi.RData")
}
run.gbm <- TRUE
source("../lib/gbmp.r")
if(run.gbm){
output_gbm <- gbmp(df.train, df.test)
output2_gbm <- gbmp(df.train2, df.test2)
save(output_gbm, file = "../output/output_gbm.RData")
save(output2_gbm, file = "../output/output2_gbm.RData")
}else{
load("../output/output_gbm.RData")
load("../output/output2_gbm.RData")
}
# Packages that will be used
packages.used <- c("corrplot", "caret", "randomForest")
# Check packages that need to be installed
packages.needed <- setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# Install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
# Load libraries
library("corrplot")
library("caret")
library("randomForest")
# Set working directory to the doc folder
setwd("~/GitHub/Spring2018-Project5-grp_2/doc")
# Load data
df <- read.csv("../data/data.csv", header = TRUE, stringsAsFactors = FALSE)
# Print the head of data
head(df)
summary(df)
# Delete the first column from dataset as id won't be used, and delete last column from dataset as its entries are all NA's
df <- df[,-c(1,33)]
# Factorize the diagnosis attribute
df$diagnosis <- factor(df$diagnosis)
df$diagnosis <- as.integer(df$diagnosis)-1   # M=1 B=0
# Split entire data into 80% train set and 20% test set
set.seed(123)
index <- sample(1:nrow(df),0.8*nrow(df))
df.train <- df[index,]
df.test <- df[-index,]
# Check proportion of diagnosis (Benign/Malignant) in train/test sets
#prop.table(table(df.train$diagnosis))
#prop.table(table(df.test$diagnosis))
#library(corrplot)
corr_mat <- cor(df.train[,2:ncol(df)])
corrplot(corr_mat, method = "square", order = "hclust",
# adjust the color, size and rotation degree of the text label
tl.col = "black", tl.cex = 0.6, tl.srt = 45,
# adjust the color, format, size of the corrlation display
addCoef.col = "black", addCoefasPercent = TRUE, number.cex=0.45,
addrect = 14)
control <- trainControl(method = "repeatedcv", number = 5, repeats = 3)
model <- train(factor(diagnosis)~., data=df.train, method="rf", preProcess="scale", trControl=control)
importance <- varImp(model, scale=FALSE)
plot(importance)
feature_selected <- c("texture_worst", "area_se", "perimeter_worst",
"concave.points_worst", "concavity_worst", "fractal_dimension_se",
"concavity_se", "texture_se", "smoothness_se",
"smoothness_worst", "fractal_dimension_worst", "symmetry_se",
"symmetry_mean", "symmetry_worst")
df.train2 <- df.train[,c("diagnosis",feature_selected)]
feature_selected <- c("texture_worst", "area_se", "perimeter_worst",
"concave.points_worst", "concavity_worst", "fractal_dimension_se",
"concavity_se", "texture_se", "smoothness_se",
"smoothness_worst", "fractal_dimension_worst", "symmetry_se",
"symmetry_mean", "symmetry_worst")
df.train2 <- df.train[,c("diagnosis",feature_selected)]
#library(caret)
#library(randomForest)
control <- rfeControl(functions=rfFuncs, method="cv", number=5)
results <- rfe(df.train2[,-1],factor(df.train2[,1]),size=c(1:14),rfeControl=control)
predictors(results)
plot(results, type=c("g", "o"))
feature_selected <- c("perimeter_worst", "concave.points_worst", "area_se",
"concavity_worst", "texture_worst", "smoothness_worst",
"symmetry_worst", "concavity_se", "fractal_dimension_worst",
"symmetry_mean", "fractal_dimension_se")
df.train2 <- df.train2[,c("diagnosis",feature_selected)]
df.test2 <- df.test[,c("diagnosis",feature_selected)]
run.rf <- FALSE
source("../lib/rf.R")
if(run.rf){
output_rf <- RF(df.train,df.test)
output2_rf <- RF(df.train2,df.test2)
save(output_rf,file = "../output/output_rf.RData")
save(output2_rf,file = "../output/output2_rf.RData")
}else{
load("../output/output_rf.RData")
load("../output/output2_rf.RData")
}
run.logi <- FALSE
source("../lib/logi.R")
if(run.logi){
output_logi <- logi(df.train, df.test)
output2_logi <- logi(df.train2, df.test2)
save(output_logi, file = "../output/output_logi.RData")
save(output2_logi, file = "../output/output2_logi.RData")
}else{
load("../output/output_logi.RData")
load("../output/output2_logi.RData")
}
run.gbm <- FALSE
source("../lib/gbmp.r")
if(run.gbm){
output_gbm <- gbmp(df.train, df.test)
output2_gbm <- gbmp(df.train2, df.test2)
save(output_gbm, file = "../output/output_gbm.RData")
save(output2_gbm, file = "../output/output2_gbm.RData")
}else{
load("../output/output_gbm.RData")
load("../output/output2_gbm.RData")
}
run.xg <- FALSE
source("../lib/xgboost.r")
if(run.xg){
output_xg <- xgb(df.train,df.test)
output2_xg <- xgb(df.train2,df.test2)
save(output_xg,file = "../output/output_xg.RData")
save(output2_xg,file = "../output/output2_xg.RData")
}else{
load("../output/output_xg.RData")
load("../output/output2_xg.RData")
}
run.ada <- FALSE
source("../lib/adaboost.r")
if(run.ada){
output_ada <- adaboost(df.train,df.test)
output2_ada <- adaboost(df.train2,df.test2)
save(output_ada,file = "../output/output_ada.RData")
save(output2_ada,file = "../output/output2_ada.RData")
}else{
load("../output/output_ada.RData")
load("../output/output2_ada.RData")
}
run.svm <- FALSE
source("../lib/svm.R")
if(run.svm){
output_svm <- SVM(df.train,df.test)
output2_svm <- SVM(df.train2,df.test2)
save(output_svm,file = "../output/output_svm.RData")
save(output2_svm,file = "../output/output2_svm.RData")
}else{
load("../output/output_svm.RData")
load("../output/output2_svm.RData")
}
# compute confusion matrix
cm_rf <- confusionMatrix(output_rf$prediction,df.test$diagnosis)
cm_rf2 <- confusionMatrix(output2_rf$prediction,df.test$diagnosis)
cm_logi <- confusionMatrix(output_logi$prediction,df.test$diagnosis)
cm_logi2 <- confusionMatrix(output2_logi$prediction,df.test$diagnosis)
cm_gbm <- confusionMatrix(output_gbm$prediction,df.test$diagnosis)
cm_gbm2 <- confusionMatrix(output2_gbm$prediction,df.test$diagnosis)
cm_xg <- confusionMatrix(output_xg$prediction,df.test$diagnosis)
cm_xg2 <- confusionMatrix(output2_xg$prediction,df.test$diagnosis)
cm_ada <- confusionMatrix(output_ada$prediction,df.test$diagnosis)
cm_ada2 <- confusionMatrix(output2_ada$prediction,df.test$diagnosis)
cm_svm <- confusionMatrix(output_svm$prediction,df.test$diagnosis)
cm_svm2 <- confusionMatrix(output2_svm$prediction,df.test$diagnosis)
# visualize result
par(mfrow=c(4,3), cex.main=0.1)
fourfoldplot(cm_rf$table, conf.level = 0, margin = 1,
main = paste0("Random Forest (", round(cm_rf$overall[1]*100), "%)"))
fourfoldplot(cm_logi$table, conf.level = 0, margin = 1,
main = paste0("Logistic Regression (", round(cm_logi$overall[1]*100), "%)"))
fourfoldplot(cm_gbm$table, conf.level = 0, margin = 1,
main = paste0("GBM (", round(cm_gbm$overall[1]*100), "%)"))
fourfoldplot(cm_xg$table, conf.level = 0, margin = 1,
main = paste0("XGBoost (", round(cm_xg$overall[1]*100), "%)"))
fourfoldplot(cm_ada$table, conf.level = 0, margin = 1,
main = paste0("AdaBoost (", round(cm_ada$overall[1]*100), "%)"))
fourfoldplot(cm_svm$table, conf.level = 0, margin = 1,
main = paste0("SVM (", round(cm_svm$overall[1]*100), "%)"))
fourfoldplot(cm_rf2$table, conf.level = 0, margin = 1,
main = paste0("Random Forest (", round(cm_rf2$overall[1]*100), "%)"))
fourfoldplot(cm_logi2$table, conf.level = 0, margin = 1,
main = paste0("Logistic Regression (", round(cm_logi2$overall[1]*100), "%)"))
fourfoldplot(cm_gbm2$table, conf.level = 0, margin = 1,
main = paste0("GBM (", round(cm_gbm2$overall[1]*100), "%)"))
fourfoldplot(cm_xg2$table, conf.level = 0, margin = 1,
main = paste0("XGBoost (", round(cm_xg2$overall[1]*100), "%)"))
fourfoldplot(cm_ada2$table, conf.level = 0, margin = 1,
main = paste0("AdaBoost (", round(cm_ada2$overall[1]*100), "%)"))
fourfoldplot(cm_svm2$table, conf.level = 0, margin = 1,
main = paste0("SVM (", round(cm_svm2$overall[1]*100), "%)"))
time <- c(output_rf$time,output_logi$time,output_gbm$time,output_xg$time,output_ada$time,output_svm$time,
output2_rf$time,output2_logi$time,output2_gbm$time,output2_xg$time,output2_ada$time,output2_svm$time)
time_comparison <- matrix(time, nrow=2, byrow = TRUE,
dimnames = list(c("all_features","reduced_features"),
c("RandomForest","Logistic Regression","GBM",
"XGBoost","AdaBoost","SVM")))
round(time_comparison,2)
str(df)
# Load data
df <- read.csv("../data/data.csv", header = TRUE, stringsAsFactors = FALSE)
# Print the head of data
head(df)
#summary(df)
str(df)
summary(df)
str(df)
summary(df)
cm_rf$overall[1]
cm_rf$overall
accuracy <- c(cm_rf$overall[1],cm_logi$overall[1],cm_gbm$overall[1],
cm_xg$overall[1],cm_ada$overall[1],cm_svm$overall[1],
cm_rf2$overall[1],cm_logi2$overall[1],cm_gbm2$overall[1],
cm_xg2$overall[1],cm_ada2$overall[1],cm_svm2$overall[1])
accuracy <- c(cm_rf$overall[1],cm_logi$overall[1],cm_gbm$overall[1],
cm_xg$overall[1],cm_ada$overall[1],cm_svm$overall[1],
cm_rf2$overall[1],cm_logi2$overall[1],cm_gbm2$overall[1],
cm_xg2$overall[1],cm_ada2$overall[1],cm_svm2$overall[1])
accuracy_comparison <- matrix(accuracy, nrow = 2, byrow = TRUE)
accuracy <- c(cm_rf$overall[1],cm_logi$overall[1],cm_gbm$overall[1],
cm_xg$overall[1],cm_ada$overall[1],cm_svm$overall[1],
cm_rf2$overall[1],cm_logi2$overall[1],cm_gbm2$overall[1],
cm_xg2$overall[1],cm_ada2$overall[1],cm_svm2$overall[1])
accuracy_comparison <- matrix(accuracy, nrow = 2, byrow = TRUE)
accuracy_comparison
accuracy <- c(cm_rf$overall[1],cm_logi$overall[1],cm_gbm$overall[1],
cm_xg$overall[1],cm_ada$overall[1],cm_svm$overall[1],
cm_rf2$overall[1],cm_logi2$overall[1],cm_gbm2$overall[1],
cm_xg2$overall[1],cm_ada2$overall[1],cm_svm2$overall[1])
accuracy_comparison <- matrix(accuracy, nrow = 2, byrow = TRUE)
round(accuracy_comparison,2)
accuracy <- c(cm_rf$overall[1],cm_logi$overall[1],cm_gbm$overall[1],
cm_xg$overall[1],cm_ada$overall[1],cm_svm$overall[1],
cm_rf2$overall[1],cm_logi2$overall[1],cm_gbm2$overall[1],
cm_xg2$overall[1],cm_ada2$overall[1],cm_svm2$overall[1])
accuracy_comparison <- matrix(accuracy, nrow = 2, byrow = TRUE)
round(accuracy_comparison,4)
accuracy <- c(cm_rf$overall[1],cm_logi$overall[1],cm_gbm$overall[1],
cm_xg$overall[1],cm_ada$overall[1],cm_svm$overall[1],
cm_rf2$overall[1],cm_logi2$overall[1],cm_gbm2$overall[1],
cm_xg2$overall[1],cm_ada2$overall[1],cm_svm2$overall[1])
accuracy_comparison <- matrix(accuracy, nrow = 2, byrow = TRUE)
round(accuracy_comparison,6)
accuracy <- c(cm_rf$overall[1],cm_logi$overall[1],cm_gbm$overall[1],
cm_xg$overall[1],cm_ada$overall[1],cm_svm$overall[1],
cm_rf2$overall[1],cm_logi2$overall[1],cm_gbm2$overall[1],
cm_xg2$overall[1],cm_ada2$overall[1],cm_svm2$overall[1])
accuracy_comparison <- matrix(accuracy, nrow = 2, byrow = TRUE)
round(accuracy_comparison,4)
# Load data
df <- read.csv("../data/data.csv", header = TRUE, stringsAsFactors = FALSE)
# Delete the first column from dataset as id won't be used, and delete last column from dataset as its entries are all NA's
df <- df[,-c(1,33)]
# Factorize the diagnosis attribute
df$diagnosis <- factor(df$diagnosis)
df$diagnosis <- as.integer(df$diagnosis)-1   # M=1 B=0
# Split entire data into 80% train set and 20% test set
set.seed(123)
index <- sample(1:nrow(df),0.8*nrow(df))
df.train <- df[index,]
df.test <- df[-index,]
# Check proportion of diagnosis (Benign/Malignant) in train/test sets
#prop.table(table(df.train$diagnosis))
#prop.table(table(df.test$diagnosis))
feature_selected <- c("texture_worst", "area_se", "perimeter_worst",
"concave.points_worst", "concavity_worst", "fractal_dimension_se",
"concavity_se", "texture_se", "smoothness_se",
"smoothness_worst", "fractal_dimension_worst", "symmetry_se",
"symmetry_mean", "symmetry_worst")
df.train2 <- df.train[,c("diagnosis",feature_selected)]
traindata <- df.train
n<-names(traindata)
gbm.form <- as.formula(paste("diagnosis ~",
paste(n[!n %in% "diagnosis"],
collapse = " + ")))
gbmCV = gbm(formula = gbm.form,
distribution = "bernoulli",
data = traindata,
n.trees = 500,
shrinkage = .1,
n.minobsinnode = 15,
cv.folds = 5,
n.cores = 1)
library(gbm)
gbmCV = gbm(formula = gbm.form,
distribution = "bernoulli",
data = traindata,
n.trees = 500,
shrinkage = .1,
n.minobsinnode = 15,
cv.folds = 5,
n.cores = 1)
optimalTreeNumberPredictionCV = gbm.perf(gbmCV)
optimalTreeNumberPredictionCV
traindata <- df.train2
n<-names(traindata)
gbm.form <- as.formula(paste("diagnosis ~",
paste(n[!n %in% "diagnosis"],
collapse = " + ")))
gbmCV = gbm(formula = gbm.form,
distribution = "bernoulli",
data = traindata,
n.trees = 500,
shrinkage = .1,
n.minobsinnode = 15,
cv.folds = 5,
n.cores = 1)
optimalTreeNumberPredictionCV = gbm.perf(gbmCV)
optimalTreeNumberPredictionCV
