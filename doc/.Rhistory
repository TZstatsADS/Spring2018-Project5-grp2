# Packages that will be used
packages.used <- c("PerformanceAnalytics", "ggplot2")
# Check packages that need to be installed
packages.needed <- setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# Install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
# Load libraries
library("PerformanceAnalytics")
library("ggplot2")
# Set working directory to the doc folder
setwd("~/GitHub/Spring2018-Project5-grp_2/doc")
df <- read.csv("../data/data.csv", header = TRUE, stringsAsFactors = FALSE)
head(df)
str(df)
summary(df)
# Delete last column from dataset as its entries are all NA's
df <- df[,-1]
# Factorize the diagnosis attribute
df$diagnosis <- factor(ifelse(df$diagnosis=="B","Benign","Malignant"))
# Split entire data into 80% train set and 20% test set
set.seed(123)
index <- sample(1:nrow(df),0.8*nrow(df))
df.train <- df[index,]
df.test <- df[-index,]
# Check proportion of diagnosis (Benign/Malignant) in train/test sets
#prop.table(table(df.train$diagnosis))
#prop.table(table(df.test$diagnosis))
df <- read.csv("../data/data.csv", header = TRUE, stringsAsFactors = FALSE)
# Delete first column from dataset because it has no use,and delete last column from dataset as its entries are all NA's
df <- df[,-c(1,33)]
# Factorize the diagnosis attribute
df$diagnosis <- factor(ifelse(df$diagnosis=="B","Benign","Malignant"))
# Split entire data into 80% train set and 20% test set
set.seed(123)
index <- sample(1:nrow(df),0.8*nrow(df))
df.train <- df[index,]
df.test <- df[-index,]
# Check proportion of diagnosis (Benign/Malignant) in train/test sets
#prop.table(table(df.train$diagnosis))
#prop.table(table(df.test$diagnosis))
df
as.integer(df$diagnosis)-1
df$diagnosis
df$diagnosis <- as.integer(df$diagnosis)-1   #M=1 B=0
df
xgb.Dmatrix
library(xgboost)
xgtrain <- xgb.DMatrix(as.matrix(df.train %>% select(-diagnosis)), label = df.train$diagnosis)
xgtest  <- xgb.DMatrix(as.matrix(df.test  %>% select(-diagnosis,-predicted)), label = df.test$diagnosis)
library(magrittr)
xgtrain <- xgb.DMatrix(as.matrix(df.train %>% select(-diagnosis)), label = df.train$diagnosis)
xgtest  <- xgb.DMatrix(as.matrix(df.test  %>% select(-diagnosis,-predicted)), label = df.test$diagnosis)
library(dplyr)
## create xgb.DMatrix objects for each trainand test set.
xgtrain <- xgb.DMatrix(as.matrix(df.train %>% select(-diagnosis)), label = df.train$diagnosis)
xgtest  <- xgb.DMatrix(as.matrix(df.test  %>% select(-diagnosis,-predicted)), label = df.test$diagnosis)
xgtrain <- xgb.DMatrix(as.matrix(df.train %>% select(-diagnosis)), label = df.train$diagnosis)
xgtest  <- xgb.DMatrix(as.matrix(df.test  %>% select(-diagnosis)), label = df.test$diagnosis)
params <- list("objective"        = "binary:logistic",
"eval_metric"      = "auc",
"eta"              = 0.012,
"subsample"        = 0.8,
"max_depth"        = 8,
"colsample_bytree" = 0.9,
"min_child_weight" = 5
)
nRounds <- 5000
earlyStoppingRound <- 100
printEveryN = 100
model_xgb.cv <- xgb.cv(params = params,
data = xgtrain,
maximize = TRUE,
nfold = 5,
nrounds = 5000,
nthread = 1,
early_stopping_round = 100,
print_every_n = 100)
df.train$diagnosis
df$diagnosis <- as.integer(df$diagnosis)-1
xgtrain <- xgb.DMatrix(as.matrix(df.train %>% select(-diagnosis)), label = df.train$diagnosis)
xgtest  <- xgb.DMatrix(as.matrix(df.test  %>% select(-diagnosis)), label = df.test$diagnosis)
model_xgb.cv <- xgb.cv(params = params,
data = xgtrain,
maximize = TRUE,
nfold = 5,
nrounds = 5000,
nthread = 1,
early_stopping_round = 100,
print_every_n = 100)
df.test$diagnosis
as.integer(df$diagnosis)-1
df$diagnosis
df <- read.csv("../data/data.csv", header = TRUE, stringsAsFactors = FALSE)
# Delete first column from dataset because it has no use,and delete last column from dataset as its entries are all NA's
df <- df[,-c(1,33)]
# Factorize the diagnosis attribute
df$diagnosis <- factor(ifelse(df$diagnosis=="B","Benign","Malignant"))
df$diagnosis <- as.integer(df$diagnosis)-1   #M=1 B=0
# Split entire data into 80% train set and 20% test set
set.seed(123)
index <- sample(1:nrow(df),0.8*nrow(df))
df.train <- df[index,]
df.test <- df[-index,]
# Check proportion of diagnosis (Benign/Malignant) in train/test sets
#prop.table(table(df.train$diagnosis))
#prop.table(table(df.test$diagnosis))
df.test$diagnosis
xgtrain <- xgb.DMatrix(as.matrix(df.train %>% select(-diagnosis)), label = df.train$diagnosis)
xgtest  <- xgb.DMatrix(as.matrix(df.test  %>% select(-diagnosis)), label = df.test$diagnosis)
model_xgb.cv <- xgb.cv(params = params,
data = xgtrain,
maximize = TRUE,
nfold = 5,
nrounds = 5000,
nthread = 1,
early_stopping_round = 100,
print_every_n = 100)
model_xgb.cv$evaluation_log
d <- model_xgb.cv$evaluation_log
n <- nrow(d)
v <- model_xgb.cv$best_iteration
dat <- data.frame(x=rep(d$iter, 2), val=c(d$train_auc_mean, d$test_auc_mean), set=rep(c("train", "test"), each=n))
ggplot(data = df, aes(x=x, y=val)) +
geom_line(aes(colour=set)) +
geom_vline(xintercept=v) +
theme_bw() +
labs(title="AUC values for XGBoost with cross-validation", x="Iteration", y="AUC values")
set=rep(c("train", "test"), each=n)
dat <- data.frame(x=rep(d$iter, 2), val=c(d$train_auc_mean, d$test_auc_mean), set=rep(c("train", "test"), each=n))
ggplot(data = dat, aes(x=x, y=val)) +
geom_line(aes(colour=set)) +
geom_vline(xintercept=v) +
theme_bw() +
labs(title="AUC values for XGBoost with cross-validation", x="Iteration", y="AUC values")
model_xgb <- xgboost(params = params,
data = xgtrain,
maximize = TRUE,
nrounds = 5000,
nthread = 1,
early_stopping_round = 100,
print_every_n = 100)
model_xgb$evaluation_log
ggplot(data = dat1 , aes(x=x, y=val)) +
labs(title="AUC values for XGBoost", x="Iteration", y="AUC values (train)")
d1 <- model_xgb$evaluation_log
n1 <- nrow(d1)
dat1 <- data.frame(x=rep(d$iter), val=d$train_auc)
ggplot(data = dat1 , aes(x=x, y=val)) +
labs(title="AUC values for XGBoost", x="Iteration", y="AUC values (train)")
d1 <- model_xgb$evaluation_log
n1 <- nrow(d1)
dat1 <- data.frame(x=rep(d1$iter), val=d1$train_auc)
ggplot(data = dat1 , aes(x=x, y=val)) +
labs(title="AUC values for XGBoost", x="Iteration", y="AUC values (train)")
ggplot(data = dat1, aes(x=x, y=val)) +
geom_line() +
theme_bw() +
labs(title="AUC values for XGBoost", x="Iteration", y="AUC values (train)")
ggplot(data = dat1, aes(x=x, y=val)) +
geom_line(colour = "red") +
theme_bw() +
labs(title="AUC values for XGBoost", x="Iteration", y="AUC values")
v1 <- model_xgb$best_iteration
ggplot(data = dat1, aes(x=x, y=val)) +
geom_line(colour = "red") +
geom_vline(xintercept=v1) +
theme_bw() +
labs(title="AUC values for XGBoost", x="Iteration", y="AUC values")
## Prediction
xgtest$predicted <- round(predict(object = model_xgb ,newdata = xgtest),0)
predict(object = model_xgb ,newdata = xgtest)
round(predict(object = model_xgb ,newdata = xgtest),0)
xgtest$predicted
## Prediction
xgtest$predicted <- rep(NA,nrow(xgtest))
rep(NA,nrow(xgtest))
xgtest$predicted
prediction_xg <- round(predict(object = model_xgb ,newdata = xgtest),0)
df.train
df
df.test
df.train
df.train[,1]
control <- rpart.control(cp = -1, maxdepth = 14,maxcompete = 1,xval = 0)
model_ada <- ada(diagnosis~., data = df.train, test.x = df.train[,-1], test.y = df.train[,1], type = "gentle", control = control, iter = 70)
library(rpart)
library(ada)
install.packages("ada")
library(rpart)
library(ada)
control <- rpart.control(cp = -1, maxdepth = 14,maxcompete = 1,xval = 0)
model_ada <- ada(diagnosis~., data = df.train, test.x = df.train[,-1], test.y = df.train[,1], type = "gentle", control = control, iter = 70)
prediction_ada <- predict(model_ada, df.test[,-1])
prediction_ada
cm_ada <- confusionMatrix(prediction_ada, df.test$diagnosis)
cm_ada
library(caret)
cm_ada <- confusionMatrix(prediction_ada, df.test$diagnosis)
cm_ada
