---
title: "Project 5 - Breast Cancer Classification"
author: "Group 2"
date: "4/25/2018"
output:
  html_notebook: default
  pdf_document: default
---
## Table of Contents  
[Introduction](#Intro)  
[Step 0: Load Packages & Specify Directories](#Step0)  
[Step 1: Load and Process Data](#Step1)  
[Step 2: Feature Selection](#Step2)  
[Step 3: Implement Algorithm](#Step3)  
[Step 4: Evaluation](#Step3)  

### Introduction {#Intro}   

### Step 0: Load Packages & Specify Directories {#Step0}  
```{r}
# Packages that will be used
packages.used <- c("corrplot", "caret", "randomForest")
# Check packages that need to be installed
packages.needed <- setdiff(packages.used, 
                           intersect(installed.packages()[,1], 
                                     packages.used))
# Install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE,
                   repos='http://cran.us.r-project.org')
}
# Load libraries  
library("corrplot")
library("caret")
library("randomForest")

# Set working directory to the doc folder 
setwd("~/GitHub/Spring2018-Project5-grp_2/doc")
```

### Step 1: Load and Process Data {#Step1}  
#### Load Data
```{r}
# Load data
df <- read.csv("../data/data.csv", header = TRUE, stringsAsFactors = FALSE)
```
#### Explore Data {.tabset}
##### Attribute Information  
1. ID number  
2. Diagnosis (M = malignant, B = benign)   
3-32. Ten real-valued features described as follows are computed for each cell nucleus:  
  a) radius (mean of distances from center to points on the perimeter)  
  b) texture (standard deviation of gray-scale values)  
  c) perimeter  
  d) area  
  e) smoothness (local variation in radius lengths)  
  f) compactness (perimeter^2 / area - 1.0)  
  g) concavity (severity of concave portions of the contour)  
  h) concave points (number of concave portions of the contour)   
  i) symmetry  
  j) fractal dimension ("coastline approximation" - 1)   

  The mean, standard error and "worst" or largest (mean of the three largest values) of these features   were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field    13 is Radius SE, field 23 is Worst Radius.   

33. All entries are NA's   

##### Head  
```{r}
# Print the head of data
head(df)
```

##### Summary
```{r}
summary(df)
```

#### Process Data  
```{r}
# Delete the first column from dataset as id won't be used, and delete last column from dataset as its entries are all NA's
df <- df[,-c(1,33)]

# Factorize the diagnosis attribute
df$diagnosis <- factor(df$diagnosis)
#df$diagnosis <- as.integer(df$diagnosis)-1   # M=1 B=0

# Split entire data into 80% train set and 20% test set
set.seed(123)
index <- sample(1:nrow(df),0.8*nrow(df))
df.train <- df[index,]
df.test <- df[-index,]

# Check proportion of diagnosis (Benign/Malignant) in train/test sets
#prop.table(table(df.train$diagnosis))
#prop.table(table(df.test$diagnosis))
```

### Step 2: Feature Selection {#Step2}  
```{r}
#library(corrplot)
corr_mat <- cor(df.train[,2:ncol(df)])
corrplot(corr_mat, method = "square", order = "hclust",
         # adjust the color, size and rotation degree of the text label
         tl.col = "black", tl.cex = 0.6, tl.srt = 45, 
         # adjust the color, format, size of the corrlation display
         addCoef.col = "black", addCoefasPercent = TRUE, number.cex=0.45,
         addrect = 14)
```
texture_mean, **texture_worst**  
**area_se**, radius_se, perimeter_se  
area_mean, radius_mean, perimeter_mean, area_worst, radius_worst, **perimeter_worst**  
**concave.points_worst**, concavity_mean, concave.points_mean
compactness_mean, compactness_worst, **concavity_worst**   
compactness_se, **fractal_dimension_se**  
**concavity_se**, concave.points_se  
**texture_se**  
**smoothness_se**  
smoothness_mean, **smoothness_worst**  
fractal_dimension_mean, **fractal_dimension_worst**  
**symmetry_se**  
**symmetry_mean**   
**symmetry_worst**   
```{r}
control <- trainControl(method = "repeatedcv", number = 5, repeats = 3)
model <- train(factor(diagnosis)~., data=df.train, method="rf", preProcess="scale", trControl=control)
importance <- varImp(model, scale=FALSE)
plot(importance)
```

```{r}
feature_selected <- c("texture_worst", "area_se", "perimeter_worst", 
                      "concave.points_worst", "concavity_worst", "fractal_dimension_se",
                      "concavity_se", "texture_se", "smoothness_se", 
                      "smoothness_worst", "fractal_dimension_worst", "symmetry_se", 
                      "symmetry_mean", "symmetry_worst")
df.train <- df.train[,c("diagnosis",feature_selected)]
```

```{r}
#library(caret)
#library(randomForest)
control <- rfeControl(functions=rfFuncs, method="cv", number=5)
results <- rfe(df.train[,-1],factor(df.train[,1]),size=c(1:14),rfeControl=control)
predictors(results)
plot(results, type=c("g", "o"))
```
              
```{r}
feature_selected <- c("perimeter_worst", "concave.points_worst", "area_se",
                      "concavity_worst", "texture_worst", "smoothness_worst",
                      "symmetry_worst", "concavity_se", "fractal_dimension_worst", 
                      "symmetry_mean", "fractal_dimension_se")
df.train <- df.train[,c("diagnosis",feature_selected)]
```

### Step 3: Implement Algorithm  {#Step3}  


#### algorithms {.tabset}  
##### Random Forest    
##### Logistic Regression  
##### GBM  
##### XGBoost  
##### AdaBoost  
##### SVM    

### Step 4: Evaluation  {#Step4} 