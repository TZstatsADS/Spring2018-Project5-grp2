---
title: "Project 5 - Breast Cancer Classification"
author: "Group 2"
date: "4/25/2018"
output:
  html_notebook: default
  pdf_document: default
---
## Table of Contents  
[Introduction](#Intro)  
[Step 0: Load Packages & Specify Directories](#Step0)  
[Step 1: Load and Process Data](#Step1)  
[Step 2: Feature Selection](#Step2)  
[Step 3: Implement Algorithm](#Step3)  
[Step 4: Evaluation](#Step3)  

### Introduction {#Intro}   

### Step 0: Load Packages & Specify Directories {#Step0}  
```{r}
# Packages that will be used
packages.used <- c("corrplot", "caret", "randomForest")
# Check packages that need to be installed
packages.needed <- setdiff(packages.used, 
                           intersect(installed.packages()[,1], 
                                     packages.used))
# Install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE,
                   repos='http://cran.us.r-project.org')
}
# Load libraries  
library("corrplot")
library("caret")
library("randomForest")

# Set working directory to the doc folder 
setwd("~/GitHub/Spring2018-Project5-grp_2/doc")
```

### Step 1: Load and Process Data {#Step1}  
#### Load Data
```{r}
# Load data
df <- read.csv("../data/data.csv", header = TRUE, stringsAsFactors = FALSE)
```
#### Explore Data {.tabset}
##### Attribute Information  
1. ID number  
2. Diagnosis (M = malignant, B = benign)   
3-32. Ten real-valued features described as follows are computed for each cell nucleus:  
  a) radius (mean of distances from center to points on the perimeter)  
  b) texture (standard deviation of gray-scale values)  
  c) perimeter  
  d) area  
  e) smoothness (local variation in radius lengths)  
  f) compactness (perimeter^2 / area - 1.0)  
  g) concavity (severity of concave portions of the contour)  
  h) concave points (number of concave portions of the contour)   
  i) symmetry  
  j) fractal dimension ("coastline approximation" - 1)   

  The mean, standard error and "worst" or largest (mean of the three largest values) of these features   were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field    13 is Radius SE, field 23 is Worst Radius.   

33. All entries are NA's   

##### Head  
```{r}
# Print the head of data
head(df)
```

##### Summary
```{r}
summary(df)
```

#### Process Data  
```{r}
# Delete the first column from dataset as id won't be used, and delete last column from dataset as its entries are all NA's
df <- df[,-c(1,33)]

# Factorize the diagnosis attribute
df$diagnosis <- factor(df$diagnosis)
df$diagnosis <- as.integer(df$diagnosis)-1   # M=1 B=0

# Split entire data into 80% train set and 20% test set
set.seed(123)
index <- sample(1:nrow(df),0.8*nrow(df))
df.train <- df[index,]
df.test <- df[-index,]

# Check proportion of diagnosis (Benign/Malignant) in train/test sets
#prop.table(table(df.train$diagnosis))
#prop.table(table(df.test$diagnosis))
```

### Step 2: Feature Selection {#Step2}  
```{r}
#library(corrplot)
corr_mat <- cor(df.train[,2:ncol(df)])
corrplot(corr_mat, method = "square", order = "hclust",
         # adjust the color, size and rotation degree of the text label
         tl.col = "black", tl.cex = 0.6, tl.srt = 45, 
         # adjust the color, format, size of the corrlation display
         addCoef.col = "black", addCoefasPercent = TRUE, number.cex=0.45,
         addrect = 14)
```
texture_mean, **texture_worst**  
**area_se**, radius_se, perimeter_se  
area_mean, radius_mean, perimeter_mean, area_worst, radius_worst, **perimeter_worst**  
**concave.points_worst**, concavity_mean, concave.points_mean
compactness_mean, compactness_worst, **concavity_worst**   
compactness_se, **fractal_dimension_se**  
**concavity_se**, concave.points_se  
**texture_se**  
**smoothness_se**  
smoothness_mean, **smoothness_worst**  
fractal_dimension_mean, **fractal_dimension_worst**  
**symmetry_se**  
**symmetry_mean**   
**symmetry_worst**   
```{r}
control <- trainControl(method = "repeatedcv", number = 5, repeats = 3)
model <- train(factor(diagnosis)~., data=df.train, method="rf", preProcess="scale", trControl=control)
importance <- varImp(model, scale=FALSE)
plot(importance)
```

```{r}
feature_selected <- c("texture_worst", "area_se", "perimeter_worst", 
                      "concave.points_worst", "concavity_worst", "fractal_dimension_se",
                      "concavity_se", "texture_se", "smoothness_se", 
                      "smoothness_worst", "fractal_dimension_worst", "symmetry_se", 
                      "symmetry_mean", "symmetry_worst")
df.train2 <- df.train[,c("diagnosis",feature_selected)]
```

```{r}
#library(caret)
#library(randomForest)
control <- rfeControl(functions=rfFuncs, method="cv", number=5)
results <- rfe(df.train2[,-1],factor(df.train2[,1]),size=c(1:14),rfeControl=control)
predictors(results)
plot(results, type=c("g", "o"))
```
              
```{r}
feature_selected <- c("perimeter_worst", "concave.points_worst", "area_se",
                      "concavity_worst", "texture_worst", "smoothness_worst",
                      "symmetry_worst", "concavity_se", "fractal_dimension_worst", 
                      "symmetry_mean", "fractal_dimension_se")
df.train2 <- df.train2[,c("diagnosis",feature_selected)]
df.test2 <- df.test[,c("diagnosis",feature_selected)]
```

### Step 3: Implement Algorithm  {#Step3}  


#### algorithms {.tabset}  
##### Random Forest  
```{r}
run.rf <- TRUE
source("../lib/rf.R")

if(run.rf){
  output_rf <- RF(df.train,df.test)
  output2_rf <- RF(df.train2,df.test2)
  
  save(output_rf,file = "../output/output_rf.RData")
  save(output2_rf,file = "../output/output2_rf.RData")
}else{
  load("../output/output_rf.RData")
  load("../output/output2_rf.RData")
}
```
##### Logistic Regression
```{r}
run.logi <- TRUE
source("../lib/logi.R")

if(run.logi){
  output_logi <- logi(df.train, df.test)
  output2_logi <- logi(df.train2, df.test2)
  
  save(output_logi, file = "../output/output_logi.RData")
  save(output2_logi, file = "../output/output2_logi.RData")
}else{
  load("../output/output_logi.RData")
  load("../output/output2_logi.RData")
}
```
##### GBM
```{r}
run.gbm <- TRUE
source("../lib/gbmp.r")

if(run.gbm){
  output_gbm <- gbmp(df.train, df.test)
  output2_gbm <- gbmp(df.train2, df.test2)
  
  save(output_gbm, file = "../output/output_gbm.RData")
  save(output2_gbm, file = "../output/output2_gbm.RData")
}else{
  load("../output/output_gbm.RData")
  load("../output/output2_gbm.RData")
}
```

##### XGBoost  
```{r}
run.xg <- TRUE
source("../lib/xgboost.r")

if(run.xg){
  output_xg <- xgb(df.train,df.test)
  output2_xg <- xgb(df.train2,df.test2)
  
  save(output_xg,file = "../output/output_xg.RData")
  save(output2_xg,file = "../output/output2_xg.RData")
}else{
  load("../output/output_xg.RData")
  load("../output/output2_xg.RData")
}
```
##### AdaBoost  
```{r}
run.ada <- TRUE
source("../lib/adaboost.r")

if(run.ada){
  output_ada <- adaboost(df.train,df.test)
  output2_ada <- adaboost(df.train2,df.test2)
  
  save(output_ada,file = "../output/output_ada.RData")
  save(output2_ada,file = "../output/output2_ada.RData")
}else{
  load("../output/output_ada.RData")
  load("../output/output2_ada.RData")
}
```
##### SVM    
```{r}
run.svm <- TRUE
source("../lib/svm.R")

if(run.svm){
  output_svm <- SVM(df.train,df.test)
  output2_svm <- SVM(df.train2,df.test2)
  
  save(output_svm,file = "../output/output_svm.RData")
  save(output2_svm,file = "../output/output2_svm.RData")
}else{
  load("../output/output_svm.RData")
  load("../output/output2_svm.RData")
}
```
```
### Step 4: Evaluation  {#Step4} 